{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.linalg import inv\n",
    "from copulas import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "qb = QuantBook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\"XLF\",   # Financial Select Sector SPDR Fund\n",
    "           \"COF\",   # Capital One Financial Corporation\n",
    "           \"GS\",    # Goldman Sachs Group, Inc.\n",
    "           \"JPM\",   # J P Morgan Chase & Co\n",
    "           \"WFC\"]   # Wells Fargo & Company \n",
    "symbols = [qb.AddEquity(ticker, Resolution.Daily).Symbol for ticker in tickers]\n",
    "history = qb.History(symbols, datetime(2021, 1, 1), datetime(2022, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copula test\n",
    "def permutation(n):\n",
    "    main_list=[np.concatenate([[k%2]*int((2**n)/(2**i)) for k in range(2**i)]) for i in range(1,n+1)]\n",
    "    return np.array(main_list).T*2-1\n",
    "\n",
    "def Sig(n):\n",
    "    '''\n",
    "    Sigma Matrix\n",
    "    '''\n",
    "    a=permutation(n)\n",
    "    sub = a @ a.T\n",
    "    add = n\n",
    "    F=(add+sub)/2\n",
    "    D=(add-sub)/2\n",
    "    return ((2/15)**F)*((1/30)**D)\n",
    "\n",
    "fh = lambda x,j: (x-1)*(3*x-1) if j==1 else x*(2-3*x)\n",
    "\n",
    "def Tpn(rank_df):\n",
    "    '''\n",
    "    t stats\n",
    "    '''\n",
    "    n,p=rank_df.shape\n",
    "    T_per=permutation(p)\n",
    "    pos1=fh(rank_df.div(n+1),1)\n",
    "    neg1=fh(rank_df.div(n+1),-1)\n",
    "    TNP2=[pd.DataFrame(np.where(np.array(i)==1,pos1,neg1),columns=rank_df.columns,index=rank_df.index).prod(axis=1).mean() for i in T_per]\n",
    "    return np.array(TNP2)\n",
    "\n",
    "def Independence_test(df):\n",
    "    '''\n",
    "    copula test of independence of serveral time series\n",
    "    H0: those timeseries are independent\n",
    "    return stats and p-value\n",
    "    \n",
    "    df: dataframe of (n*p) time series dataframe\n",
    "    '''\n",
    "    rank_df=df.rank()\n",
    "    n,p=rank_df.shape\n",
    "    T=Tpn(rank_df).reshape([-1,1])\n",
    "    S_inv=inv(Sig(p))\n",
    "    T_stats=(T.T@S_inv@T)[0][0]*n\n",
    "    p_value=1-stats.chi2.cdf(T_stats, p**2)\n",
    "    return T_stats,p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETF\n",
    "tickers= [\"VDE\", \"USO\", \"XES\", \"XOP\", \"UNG\", \"ICLN\", \"ERX\",\"UCO\", \"AMJ\", \"BNO\", \"AMLP\", \"TAN\", \n",
    "                \"GLD\", \"IAU\", \"SLV\", \"GDX\", \"AGQ\", \"PPLT\", \"NUGT\",\"JNUG\",\"QQQQ\",\n",
    "                \"QQQ\", \"IGV\", \"QTEC\", \"FDN\", \"FXL\", \"TECL\", \"SOXL\", \"SKYY\", \"KWEB\",\n",
    "                \"IEF\", \"SHY\", \"TLT\", \"IEI\", \"TLH\", \"BIL\", \"SPTL\",\"TMF\", \"SCHO\", \n",
    "                \"SCHR\", \"SPTS\", \"GOVT\", \"SPLV\", \"UVXY\", \"EEMV\", \"EFAV\", \"USMV\",\n",
    "                \"XLB\", \"XLE\", \"XLF\", \"XLI\", \"XLK\", \"XLP\", \"XLU\", \"XLV\", \"XLY\",\"SPY\",\"MDY\",\n",
    "                \"IEV\",\"EEM\", \"ILF\", \"VIXY\",\"ERY\", \"SCO\", \"DGAZ\",\"DUST\", \"JDST\",\"TECS\", \n",
    "                \"SOXS\",\"SHV\", \"TBT\", \"TBF\", \"TMV\",\"SVXY\",\"SQQQ\",\"TQQQ\",\n",
    "                \"VGSH\",\"VGIT\",\"VGLT\"]\n",
    "# Liquidate ETF \n",
    "symbols = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    sym = qb.AddEquity(ticker)\n",
    "    symbols.append(sym.Symbol)\n",
    "\n",
    "start_date = DateTime(2017,1,1)\n",
    "end_date =  DateTime(2021,11,1)\n",
    "history = qb.History(symbols, start_date,end_date,Resolution.Daily)['close']\n",
    "history = history.unstack(level = 0)\n",
    "log_rtns = (np.log(history) - np.log(history.shift(1))).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# financial service stock selection\n",
    "tickers = ['WFC','JPM','BRKB R735QTJ8XC9X', 'CMB R735QTJ8XC9X', 'NOB R735QTJ8XC9X', 'NB R735QTJ8XC9X', \n",
    "'V U12VRGLO8PR9', 'MA TIX2XDPLFR6T', 'RY R735QTJ8XC9X', 'GS RKEOGCOG6RFP', \n",
    "'TD R735QTJ8XC9X', 'USB R735QTJ8XC9X']\n",
    "\n",
    "symbols = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    sym = qb.AddEquity(ticker)\n",
    "    symbols.append(sym.Symbol)\n",
    "\n",
    "start_date = DateTime(2017,1,1)\n",
    "end_date =  DateTime(2018,1,1)\n",
    "history = qb.History(symbols, start_date,end_date,Resolution.Daily)['close']\n",
    "history = history.unstack(level = 0)\n",
    "log_rtns = (np.log(history) - np.log(history.shift(1))).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic material stock selection\n",
    "\n",
    "tickers = ['DOW R735QTJ8XC9X', 'LYB UQRGJ93635GL', 'ECL R735QTJ8XC9X', 'PX R735QTJ8XC9X', 'APD R735QTJ8XC9X', \n",
    "'CRHCY R735QTJ8XC9X', 'PPG R735QTJ8XC9X', 'SHW R735QTJ8XC9X', 'PCU R735QTJ8XC9X', 'FCX R735QTJ8XC9X','IYM']\n",
    "\n",
    "symbols = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    sym = qb.AddEquity(ticker)\n",
    "    symbols.append(sym.Symbol)\n",
    "\n",
    "start_date = DateTime(2017,1,1)\n",
    "end_date =  DateTime(2021,11,1)\n",
    "history = qb.History(symbols, start_date,end_date,Resolution.Daily)['close']\n",
    "history = history.unstack(level = 0)\n",
    "log_rtns = (np.log(history) - np.log(history.shift(1))).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HealthCare stock selection\n",
    "\n",
    "tickers = ['JNJ R735QTJ8XC9X', 'PFE R735QTJ8XC9X', 'MRK R735QTJ8XC9X', 'UNH R735QTJ8XC9X', 'AMGN R735QTJ8XC9X', \n",
    "'ABBV VCY032R250MD', 'MDT R735QTJ8XC9X', 'BMY R735QTJ8XC9X', 'GILD R735QTJ8XC9X', 'WAG R735QTJ8XC9X']\n",
    "\n",
    "symbols = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    sym = qb.AddEquity(ticker)\n",
    "    symbols.append(sym.Symbol)\n",
    "\n",
    "start_date = DateTime(2017,1,1)\n",
    "end_date =  DateTime(2018,1,1)\n",
    "history = qb.History(symbols, start_date,end_date,Resolution.Daily)['close']\n",
    "history = history.unstack(level = 0)\n",
    "log_rtns = (np.log(history) - np.log(history.shift(1))).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities Industry Selection\n",
    "\n",
    "tickers = ['FPL R735QTJ8XC9X', 'DUK R735QTJ8XC9X', 'SO R735QTJ8XC9X', 'D R735QTJ8XC9X', 'PE R735QTJ8XC9X', \n",
    "'AEP R735QTJ8XC9X', 'SRE RBYFBGNAJMUD', 'EIX R735QTJ8XC9X', 'PPL R735QTJ8XC9X', \n",
    "'ED R735QTJ8XC9X', 'PEG R735QTJ8XC9X', 'NSP R735QTJ8XC9X', 'WEC R735QTJ8XC9X', \n",
    "'DTE R735QTJ8XC9X', 'NU R735QTJ8XC9X']\n",
    "\n",
    "symbols = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    sym = qb.AddEquity(ticker)\n",
    "    symbols.append(sym.Symbol)\n",
    "start_date = DateTime(2017,1,1)\n",
    "end_date =  DateTime(2018,1,1)\n",
    "history = qb.History(symbols, start_date,end_date,Resolution.Daily)['close']\n",
    "history = history.unstack(level = 0)\n",
    "log_rtns = (np.log(history) - np.log(history.shift(1))).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy Industry Selection\n",
    "\n",
    "tickers = ['XON R735QTJ8XC9X',\n",
    "'SLB R735QTJ8XC9X', 'IPPIF R735QTJ8XC9X', 'P R735QTJ8XC9X', 'EOG R735QTJ8XC9X',\n",
    " 'SU R735QTJ8XC9X', 'EPD RCQZA696RIHX', 'OXY R735QTJ8XC9X', 'PSX V67S42RJBF51', 'CED RWTPESR2XAAT']\n",
    "\n",
    "symbols = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    sym = qb.AddEquity(ticker)\n",
    "    symbols.append(sym.Symbol)\n",
    "start_date = DateTime(2017,1,1)\n",
    "end_date =  DateTime(2018,1,1)\n",
    "history = qb.History(symbols, start_date,end_date,Resolution.Daily)['close']\n",
    "history = history.unstack(level = 0)\n",
    "log_rtns = (np.log(history) - np.log(history.shift(1))).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kendall Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['tau'])\n",
    "for s1 in log_rtns.columns:\n",
    "    for s2 in log_rtns.columns:\n",
    "        if s1 != s2 and (f'{s2}-{s1}' not in results.index):\n",
    "            results.loc[f'{s1}-{s2}'] = stats.kendalltau(log_rtns[s1], log_rtns[s2])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pair(pair):\n",
    "    s1 = pair[:pair.find('-')]\n",
    "    s2 = pair[pair.find('-')+1:]\n",
    "    return s1,s2\n",
    "\n",
    "selected_stocks = []\n",
    "selected_pairs = []\n",
    "tau_benchmark = 0\n",
    "\n",
    "for pair in results.loc[(results['tau']>tau_benchmark)|(results['tau']<-1*tau_benchmark),:].sort_values(by = 'tau',ascending=False).index:\n",
    "    s1,s2 = parse_pair(pair)\n",
    "    selected_pairs.append(pair)\n",
    "    if (s1 not in selected_stocks):\n",
    "        selected_stocks.append(s1)\n",
    "    if (s2 not in selected_stocks):\n",
    "        selected_stocks.append(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by=['tau'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co - integration Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import coint, adfuller\n",
    "def adf_pvalue(x,y):\n",
    "    x = np.log(x)\n",
    "    y = np.log(y)\n",
    "\n",
    "    X = sm.add_constant(x)\n",
    "    model = sm.OLS(y,X)\n",
    "    results = model.fit()\n",
    "\n",
    "    sigma = math.sqrt(results.mse_resid)\n",
    "\n",
    "    results = model.fit()\n",
    "\n",
    "    slope = results.params[1]\n",
    "    intercept = results.params[0]\n",
    "\n",
    "    res = results.resid\n",
    "    zscore = res/sigma\n",
    "    adf = adfuller(res)\n",
    "    \n",
    "    return adf[:2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coint_dig = pd.DataFrame(columns=['p_value'])\n",
    "for pair in selected_pairs:\n",
    "    s1,s2 = parse_pair(pair)\n",
    "    stock1,stock2 = history[s1],history[s2]\n",
    "    coint_dig.loc[f'{s1}-{s2}'] = adf_pvalue(stock1.values,stock2.values)\n",
    "    coint_dig.loc[f'{s2}-{s1}'] = adf_pvalue(stock2.values,stock1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coint_dig[coint_dig['p_value']<0.01].sort_values(by='p_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pairs = coint_dig[coint_dig['p_value']<0.01].sort_values(by='p_value').index.to_list()\n",
    "selected_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ Plot Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.distributions.empirical_distribution import ECDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_dig_distance(pair):\n",
    "    \n",
    "    s1,s2 = parse_pair(pair)\n",
    "    stock1,stock2 = log_rtns[s1],log_rtns[s2]\n",
    "\n",
    "    ecdf_x,ecdf_y = ECDF(stock1),ECDF(stock2)\n",
    "    u, v = ecdf_x(stock1), ecdf_x(stock2)\n",
    "\n",
    "    total_dig = 0\n",
    "\n",
    "    for x,y in zip(u,v):\n",
    "        \n",
    "        p3=np.array([x,y])\n",
    "        p1=np.array([0,0])\n",
    "        p2=np.array([1,1])\n",
    "        dig_distance = np.abs(np.linalg.norm(np.cross(p2-p1, p1-p3)))/np.linalg.norm(p2-p1)\n",
    "\n",
    "        total_dig += dig_distance\n",
    "\n",
    "    return total_dig/len(u)\n",
    "\n",
    "dig_dist = pd.DataFrame(columns=['QQplot'])\n",
    "for pair in selected_pairs:\n",
    "    s1,s2 = parse_pair(pair)\n",
    "    dig_dist.loc[f'{s1}-{s2}'] = cal_dig_distance(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dig_dist.sort_values(by='QQplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_stocks = []\n",
    "selected_pairs = []\n",
    "\n",
    "for pair in dig_dist.loc[dig_dist['QQplot']<1,:].sort_values(by='QQplot').index:\n",
    "    s1,s2 = parse_pair(pair)\n",
    "    selected_pairs.append(pair)\n",
    "    if (s1 not in selected_stocks):\n",
    "        selected_stocks.append(s1)\n",
    "    if (s2 not in selected_stocks):\n",
    "        selected_stocks.append(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dig_dist.sort_values(by='QQplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in ['ABBV VCY032R250MD-BMY R735QTJ8XC9X']:\n",
    "    s1,s2 = parse_pair(pair)\n",
    "    stock1,stock2 = log_rtns[s1],log_rtns[s2]\n",
    "\n",
    "    ecdf_x,ecdf_y = ECDF(stock1),ECDF(stock2)\n",
    "    u, v = ecdf_x(stock1), ecdf_x(stock2)\n",
    "\n",
    "    plt.scatter(u,v)\n",
    "    plt.axline([0, 0], [1, 1],c = 'red')\n",
    "    plt.title(pair)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copula Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pairs =coint_dig[coint_dig['p_value']<0.01].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copula_dig = pd.DataFrame(columns=['test_stats'])\n",
    "\n",
    "for pair in selected_pairs:\n",
    "\n",
    "    s1,s2 = parse_pair(pair)\n",
    "    data = log_rtns[[s1,s2]]\n",
    "    copula_dig.loc[f'{s1}-{s2}'] = Independence_test(data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "copula_dig.sort_values(by = 'test_stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for pair in selected_pairs:\n",
    "    s1,s2 = parse_pair(pair)\n",
    "    stock1,stock2 = log_rtns[s1],log_rtns[s2]\n",
    "\n",
    "    ecdf_x,ecdf_y = ECDF(stock1),ECDF(stock2)\n",
    "    u, v = ecdf_x(stock1), ecdf_x(stock2)\n",
    "\n",
    "    plt.scatter(u,v)\n",
    "    plt.axline([0, 0], [1, 1],c = 'red')\n",
    "    plt.title(pair)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dist = pd.DataFrame(columns=['ED'])\n",
    "for pair in selected_pairs:\n",
    "    s1,s2 = parse_pair(pair)\n",
    "    stock1,stock2 = log_rtns[s1],log_rtns[s2]\n",
    "    dist.loc[f'{s1}-{s2}'] = np.linalg.norm(stock1-stock2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dist.sort_values(by='ED',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "marginals_df = pd.DataFrame(index=selected_stocks, columns=['Distribution', 'AIC', 'BIC', 'KS_pvalue'])\n",
    "\n",
    "for stock in selected_stocks:\n",
    "    data = log_rtns[stock]\n",
    "    dists = ['Normal', \"Student's t\", 'Logistic', 'Extreme','Uniform']\n",
    "    best_aic = np.inf\n",
    "    for dist,name in zip([stats.norm, stats.t, stats.genlogistic, stats.genextreme,stats.uniform], dists):\n",
    "        params = dist.fit(data)\n",
    "        dist_fit = dist(*params)\n",
    "        log_like = np.log(dist_fit.pdf(data)).sum()\n",
    "        aic = 2*len(params) - 2 * log_like\n",
    "        if aic<best_aic:\n",
    "            best_dist = name\n",
    "            best_aic = aic\n",
    "            best_bic = len(params) * np.log(len(data)) - 2 * log_like\n",
    "            ks_pval = stats.kstest(data, dist_fit.cdf, N=100)[1]\n",
    "            \n",
    "    marginals_df.loc[stock] = [best_dist, best_aic, best_bic, ks_pval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from copulas.multivariate.gaussian import GaussianMultivariate\n",
    "from copulas.bivariate.clayton import Clayton\n",
    "from copulas.bivariate.frank import Frank\n",
    "from copulas.bivariate.gumbel import Gumbel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "copulas_df = pd.DataFrame(index=selected_pairs, columns=['copula', 'aic'])\n",
    "returns_form = log_rtns\n",
    "\n",
    "for pair in selected_pairs:\n",
    "    s1,s2 = parse_pair(pair)\n",
    "    # fit marginals\n",
    "    params_s1 = stats.t.fit(returns_form[s1])\n",
    "    dist_s1 = stats.t(*params_s1)\n",
    "    params_s2 = stats.t.fit(returns_form[s2])\n",
    "    dist_s2 = stats.t(*params_s2)\n",
    "    # apply probability integral transform\n",
    "    u = dist_s1.cdf(returns_form[s1])\n",
    "    v = dist_s2.cdf(returns_form[s2])\n",
    "    \n",
    "    best_aic = np.inf\n",
    "\n",
    "    for copula in [GaussianMultivariate(),Clayton(), Gumbel(), Frank()]:\n",
    "        data = pd.DataFrame(np.array([u,v]).T,columns=['u','v'])\n",
    "        copula.fit(data.values)\n",
    "        L = copula.log_probability_density(data.values).sum()\n",
    "        aic = 2 - 2 * L\n",
    "        print(aic)\n",
    "        if aic < best_aic:\n",
    "            best_aic = aic\n",
    "            best_copula = str(copula)\n",
    "            \n",
    "    copulas_df.loc[pair] = [best_copula,best_aic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "copulas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "copula = Clayton()\n",
    "copula.fit(data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "log_prob = copula.log_probability_density(data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "log_prob = log_prob[~np.c(log_prob)].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "copula.partial_derivative(data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "copula.partial_derivative(data[['v','u']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "s1,s2 = parse_pair(pair)\n",
    "s3 = 'VDE T2FCD04TATET'\n",
    "# fit marginals\n",
    "params_s1 = stats.t.fit(returns_form[s1])\n",
    "dist_s1 = stats.t(*params_s1)\n",
    "params_s2 = stats.t.fit(returns_form[s2])\n",
    "dist_s2 = stats.t(*params_s2)\n",
    "params_s3 = stats.t.fit(returns_form[s3])\n",
    "dist_s3 = stats.t(*params_s3)\n",
    "# apply probability integral transform\n",
    "u = dist_s1.cdf(returns_form[s1])\n",
    "v = dist_s2.cdf(returns_form[s2])\n",
    "y = dist_s3.cdf(returns_form[s3])\n",
    "\n",
    "data = pd.DataFrame(np.array([u,v,y]).T,columns=['u','v','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from copulas.multivariate.vine import VineCopula\n",
    "copula = VineCopula('center')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
